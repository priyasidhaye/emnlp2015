\section{Background and Related Work}
\label{sec:background}

With the increase in the number of users on Twitter, there has also been an increase in the number of studies on Twitter data, towards classifying and summarizing text, identifying intents of tweets, event summarization, and so on. \newcite{ghosh2011entropy} classified the retweeting activity of users based on entropy. The study considered the occurrence of the same URL in a different tweet as a ‘retweet’, and was able to separate the tweets as automatic or robotic retweeting, campaigns, news, blogs and so on. The study shows some interesting trends of retweeting activity for each of these cases. In another study, \newcite{chen2012extracting}, were able to extract sentiment expressions based on their corpus of tweets, that resulted in extraction of both formal and slang sentiment bearing words.

Other studies using Twitter data include \newcite{o2010tweetmotif}, who use topic summarization for a given search for better browsing. \newcite{chakrabarti2011event} generate an event summary by learning about the event using a Hidden Markov Model over the tweets describing it. \newcite{wang2014socially} generate a coherent event summary by treating summarization as an optimization problem for topic cohesion. \newcite{inouye2011comparing} compare multiple summarization techniques to generate a summary of multi-post blogs on Twitter.

Studies on classifying user intents in tweets are interpreted in different ways. \newcite{banerjee2012towards} analyze real time data to detect presence of intents in tweets. \newcite{wang2015mining} classify intents as food and drink, travel, career and so on, ones that can directly be used as intents for purchasing and can be utilized for advertisements. They also They focus on finding tweets with intent and then classying those. \newcite{gomez2014content} use features from text and stylistics to determine user intentions, which are classified as news report, opinion, publicity and so on. \newcite{mohammad2013identifying} study the classification of user intents specifically for tweets related to elections. They study one election and classify tweets as ones that agree or disagree with the candidate, ones that are meant for humor, support and so on. 

As described in \secref{sec:intro}, we analyze tweet generation using extractive summarization techniques. There has been one such study comparing different text summarization techniques for tweet generation by  \newcite{lloret2013towards}. Summarization systems were used to summarize texts to sentences and then were compared against each other, evaluated using the ROUGE metric for evaluation. The ROUGE-1, ROUGE-2 and ROUGE-L metrics were used and the tweets were compared against an ideal summary. ROUGE \cite{lin2004rouge} is a recall based n-gram counting evaluation metric developed for summarization \cite{nenkova2006summarization}. However, it reflects the summarization quality better when used with multiple reference texts and is not meant to be used at the sentence level. However, since extractive summarization algorithms are being compared, ROUGE is used for the evalutation.

The limits of extractive summarization have been studied by \newcite{he2000comparing} by comparing user preferences for multiple types of summaries for an audio-visual presentation. They demonstrate that the most preferred method of summarization is highlights and notes provided by the author, rather than transcripts or slides from the presentation. \newcite{conroy2006topic} have defined an oracle score towards the same aim. The oracle score is based on the maximum likelihood probability of words occuring in model summaries and is in turn used to generate summaries that perform better than any extracted and also human-generated summaries. These studies show that extractive summarization algorithms may not generate good quality summaries even after giving high ROUGE evaluation scores. 


