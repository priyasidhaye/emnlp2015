\section{Interaction with Formality}

As seen in the results of the analyses performed in \secref{sec:analysis}, the tweets have little in common with the articles they are linked to. This shows that extractive summarization algorithms can only recover a small proportion of the indicative tweets. 

To tie in the results of the findings above with some intuitive notions about the text and see how formality interacts with the results, we also calculated the formality of the articles. This formality score was correlated with the longest common subsequence measure that we defined above. 

We assume that the formality of an article can be estimated by the formality of the words and phrases in the article. We used the formality lexicon of \newcite{brooke2013multi}. They calculate formality scores for words and sentences by training a model on a large corpus based on the appearance of words in specific documents. Their model represents words as vectors and the formal and informal seeds appear in opposite halves of the graphs, suggesting that we can use these seeds to determine if an article is formal or informal. The lexicon consists of words and phrases and their degree of formality. Thus, more formal words are marked on a positive scale and informal words like those occurring in colloquial language are marked on a negative scale. 

Let the set of formality expressions from the lexicon be $L$, and the formality score for an expression $e$ be $\textit{score}(e)$. Let the set of all substrings from the article $\textit{substrings}(a)$ be $S$. Then, the formality score $f$ for an article $a$ is the number of formal expressions per 10 words in article is   

\begin{equation}
f = \frac{\sum\limits_{e \in L \& e \in S} \textit{score}(e)}{| \textit{unigrams}(a) |} * 10
\end{equation}

The formality lexicon gave positive weights for formal expressions and negative for informal expressions. When we computed $f$ using both formal and informal expressions, we found that the informal words predominated and ``swamped'' the signal of the formal words, leading to incomprehensible results. Thus, we discarded the informal words and used only the weights from the formal words in our final calculations. To check that these formality scores made sense intuitively, we calculated the average formality score for the articles belonging to each hashtag and ordered them, as shown in \tabref{tab:formal}.

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|}
\hline
Lowest  & Highest  \\ \hline
\#theforceawakens       & \#KevinVickers           \\
\#TaylorSwift           & \#erdogan                \\
\#winteriscoming        & \#apec                  \\ \hline
\end{tabular}
\captionof{table}{Table of hashtags (broadly, topics) with highest and lowest formality according to the lexicon.}
\label{tab:formal}
\end{table}

This formality score for each article was correlated with the percentage of match obtained using the longest common subsequence algorithm. The Pearson correlation value was 0.41, with a p-value of 7.08e-66, indicating that the interaction between formality and overlap was highly significant. Hence, we can say that the more formal the subject or the article, the better the tweet can be extracted from the article. \tabref{tab:formal} gives an example of the formality of the article, which is a low 4.2 formality words per 10 words, where the tweet is not extracted from the article, but rephrased from the article instead.

\begin{table}[htbp]
\centering
\begin{tabular}{|p{0.1\linewidth}|p{0.8\linewidth}|}
\hline
Tweet &  @globetoronto: Why Buffalo got clobbered with snow and Toronto did not. \#weather \#snowstorm http://t.co/gcwwoDPZmX... http://t.co/BXY7EH6F3u" \\ \hline
Title & What caused Buffaloâ€™s massive snow and why Toronto got lucky \\  \hline
Text  & Torontonians have long been the butt of jokes about calling in the army every time a few snow flurries whip by... \\ \hline
\end{tabular}
\captionof{table}{Example of a tweet, title of the article where the formality of the article is over the mean, and the tweet is extracted from the article.}
\label{tab:formal}
\end{table}

This could be explained by the fact that less formal tweets would have more abbreviations and less formal language with a lot more out of vocabulary words, and extensions of words, causing less overlap. It could be countered by normalizing the tweet text and then calculating the overlap, which we intend to do in the future.


\section{Discussions}
Having presented the above statistics showing that only a small portion of indicative tweets can be recovered from the article they link to if viewed as an extractive summarization problem, the question then becomes, how should we view the process of tweet generation?

We think that one promising direction is to model more explicitly the intent, or the purpose of the tweets. There have been several studies on classifying intents in tweets, but in many cases the intents are general, high-level intents of the tweets, more akin to classifying the topic or genre of the tweet than the intent. \newcite{wang2015mining} classify intents as food and drink, travel, career and so on, ones that can directly be used as intents for purchasing and can be utilized for advertisements. They also focus on finding tweets with intent and then classifying those. \newcite{banerjee2012towards} analyze real time data to detect presence of intents in tweets. \newcite{gomez2014content} use features from text and stylistics to determine user intentions, which are classified as news report, opinion, publicity and so on. \newcite{mohammad2013identifying} study the classification of user intents specifically for tweets related to elections. They study one election and classify tweets as ones that agree or disagree with the candidate, ones that are meant for humour, support and so on. 

These definitions of intent, while a promising start, will not be sufficient for tweet generation. For this purpose, intent would be the reason the user chose to share the article with that particular text. This would include reasons like support some cause, promote a product or an article, agree or disagree with an event, or express an opinion about it. Identifying these intents will help provide parameters for generating tweets. 