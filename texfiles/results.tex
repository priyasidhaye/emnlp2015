\section{Results}
\todo{Discuss
* Implication of results - tweet can't be extracted

* Correlation of formality and lcs scores
}

As seen from the results of the analyses performed earlier, the tweets have little in common with the articles they are related to. The analyses are based on the ROUGE-1,2 and L. This shows that extractive summarization algorithms cannot be directly applied to articles to generate tweets. \improvement{expand motive behind calculating formality scores }

We also calculated the formality of the articles to correlate it with the longest common subsequence. To achieve this, the degree of formality of the text was calculated with the help of some other studies. The formality lexicon was generated by \newcite{brooke2013multi} and can be used to measure formality of a given text. The lexicon consists of words and phrases and the degree of formality for their occurrence. Thus, more formal words are marked on a positive scale and informal words like those occurring in colloquial language are marked on a negative scale. The degree of formality was calculated using this lexicon.

\begin{equation}
\resizebox{.9\hsize}{!}{$formalityScore = \frac{| unigramsArticle \cap formalitySet |}{| unigramsArticle |} * 10$}
\end{equation}

The formality lexicon gave positive weights for formal expressions and negative for informal expressions. After calculating the formality weights for all articles, it was observed that they all had a total negative normalized weight, meaning a lot more informal expressions were getting matched. Hence, we used just the formal word occurrences for calculating the weight. Thus, above a certain cut-off weight, the article could be considered formal, else would be considered informal. To make sure these formality scores intuitively made sense, we calculated the average formality score for each hashtag used in the search during data extraction and ordered them, shown in \tabref{tab:formal}


\begin{table}[h]
\begin{tabular}{l|l}
\hline
Lowest formality scores & Highest formality scores \\ \hline
\#theforceawakens       & \#KevinVickers           \\
\#TaylorSwift           & \#erdogan                \\
\#winteriscoming        & \#apec                  
\end{tabular}
\label{tab:formal}
\end{table}

This formality score for each article was then correlated with the percentage of match obtained using the longest common subsequence algorithm. The Pearson correlation value was 0.41, with a p-value of 7.08e-66. The p-value justifies that we can reject the null hypothesis, and say with confidence that there is a correlation between the formality scores and the ROUGE-L scores of the tweets and articles. Hence, we can say that the more formal the subject or the article, there are higher chances of the tweet being extracted directly from the article. \improvement{explain this better}